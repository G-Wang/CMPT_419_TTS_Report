
# CMPT 419 (Machine Learning) class Final Report
Fall 2018 term, arxiv submission in progress.

# Abstract
Modified RNN based Seq2Seq Architecture (i.e Tacotron) to reduce model size and help speed up training, the following is implemented:

1. Self attention (Similar to transformer paper)
2. Guided Attention & Forced incremental Attention (From DCTTS paper)
3. grapheme & Phoneme mixing input

# Audio Samples
Listen to audio samples [here](https://soundcloud.com/gary-wang-23/sets/tts-samples-for-cmpt-419).
